{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_age_from_filename(filename):\n",
    "    try:\n",
    "        parts = filename.split('_')\n",
    "        dob_str = parts[1]\n",
    "        photo_taken_year_str = parts[2].split('.')[0]\n",
    "        \n",
    "        # Validate and parse the date of birth string\n",
    "        if re.match(r'\\d{4}-\\d{2}-\\d{2}', dob_str) is None:\n",
    "            return None\n",
    "        \n",
    "        dob = datetime.strptime(dob_str, '%Y-%m-%d')\n",
    "        photo_taken_year = int(photo_taken_year_str)\n",
    "        \n",
    "        age = photo_taken_year - dob.year\n",
    "        if dob.month > 1 or (dob.month == 1 and dob.day > 1):  # If birthday hasn't occurred yet this year\n",
    "            age -= 1\n",
    "        \n",
    "        return age\n",
    "    except Exception as e:\n",
    "        # Return None for invalid date formats\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeDataGenerator(Sequence):\n",
    "    def __init__(self, image_filenames, labels, batch_size, img_size, base_img_dir):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.base_img_dir = base_img_dir\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return np.array([self.preprocess_image(file_name) for file_name in batch_x]), np.array(batch_y)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def preprocess_image(self, file_name):\n",
    "        img_path = os.path.join(self.base_img_dir, file_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"File not found: {img_path}\")\n",
    "        img = image.load_img(img_path, target_size=self.img_size)\n",
    "        img = image.img_to_array(img)\n",
    "        img /= 255.0\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img_dir = './wiki_crop'\n",
    "folders = [str(i).zfill(2) for i in range(100)]\n",
    "image_filenames = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_img_dir, folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        image_filenames += [os.path.join(folder, fname) for fname in os.listdir(folder_path)]\n",
    "\n",
    "ages = [extract_age_from_filename(os.path.basename(f)) for f in image_filenames]\n",
    "\n",
    "# Filter out None values from ages and corresponding filenames\n",
    "valid_data = [(f, age) for f, age in zip(image_filenames, ages) if age is not None]\n",
    "image_filenames, labels = zip(*valid_data)\n",
    "\n",
    "batch_size = 32\n",
    "img_size = (128, 128)\n",
    "\n",
    "data_generator = AgeDataGenerator(image_filenames, labels, batch_size, img_size, base_img_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Program Files\\Python\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "model = create_cnn_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model_checkpoints/epoch-{epoch:02d}_mae-{val_mae:.2f}.keras'\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False, save_best_only=True, monitor='val_mae', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m1947/1947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 291ms/step - loss: 13.2525 - mae: 13.2525 - val_loss: 11.5787 - val_mae: 11.5787\n",
      "Epoch 2/8\n",
      "\u001b[1m1947/1947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 155ms/step - loss: 12.0245 - mae: 12.0245 - val_loss: 11.0971 - val_mae: 11.0971\n",
      "Epoch 3/8\n",
      "\u001b[1m1947/1947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 157ms/step - loss: 11.5028 - mae: 11.5028 - val_loss: 10.6224 - val_mae: 10.6224\n",
      "Epoch 4/8\n",
      "\u001b[1m1947/1947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 155ms/step - loss: 10.9906 - mae: 10.9906 - val_loss: 10.0428 - val_mae: 10.0428\n",
      "Epoch 5/8\n",
      "\u001b[1m1947/1947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 155ms/step - loss: 10.5255 - mae: 10.5255 - val_loss: 9.6640 - val_mae: 9.6640\n",
      "Epoch 6/8\n",
      "\u001b[1m1947/1947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 155ms/step - loss: 10.3609 - mae: 10.3609 - val_loss: 9.7129 - val_mae: 9.7129\n",
      "Epoch 7/8\n",
      "\u001b[1m1947/1947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 156ms/step - loss: 10.0319 - mae: 10.0319 - val_loss: 8.9336 - val_mae: 8.9336\n",
      "Epoch 8/8\n",
      "\u001b[1m1947/1947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 155ms/step - loss: 9.8583 - mae: 9.8583 - val_loss: 9.1993 - val_mae: 9.1993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24907103e60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_generator, epochs=8, callbacks=[checkpoint_callback], validation_data=data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1947/1947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 35ms/step - loss: 9.1622 - mae: 9.1622\n",
      "Mean Absolute Error (MAE) on the dataset: 9.20\n"
     ]
    }
   ],
   "source": [
    "# Assuming the model and data_generator are already defined and the model is trained\n",
    "scores = model.evaluate(data_generator, verbose=1)\n",
    "print(f'Mean Absolute Error (MAE) on the dataset: {scores[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "The predicted age for the sample image is: 55.94 years\n"
     ]
    }
   ],
   "source": [
    "def predict_age(image_path, model, img_size=(128, 128)):\n",
    "    img = image.load_img(image_path, target_size=img_size)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img /= 255.0\n",
    "    \n",
    "    predicted_age = model.predict(img)\n",
    "    return predicted_age[0][0]\n",
    "\n",
    "sample_image_path = './wiki_crop/14/39014_1896-10-30_1980.jpg'\n",
    "predicted_age = predict_age(sample_image_path, model)\n",
    "print(f'The predicted age for the sample image is: {predicted_age:.2f} years')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
